{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "categorical_cols = df.select_dtypes(include=['object', 'category'])#.columns.difference(exclude_cols)\n",
    "\n",
    "# Label Encoding for categorical columns\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Defining X and y\n",
    "X = df.drop([\"RISK_DEATH\", \"DTA NASC_ano\", \"DIAS NA INSTITUICAO\", \"OBITO\", \"INT DES DESTINO\", \"4_IDADE\"], axis=1)\n",
    "y = df[\"RISK_DEATH\"]\n",
    "# Splitting the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "# Applying SMOTE to balance classes in the training set\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Normalizing the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_resampled_normalized = scaler.fit_transform(X_train_resampled)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "\n",
    "# Using SelectFromModel with GradientBoostingClassifier for feature selection\n",
    "selector = SelectFromModel(estimator=GradientBoostingClassifier(), threshold=-np.inf, max_features=11)\n",
    "selector.fit(X_train_resampled_normalized, y_train_resampled)\n",
    "selected_features_indices = np.where(selector.get_support())[0]\n",
    "\n",
    "# Using saved indices to select relevant features\n",
    "X_train_selected = X_train_resampled_normalized[:, selected_features_indices]\n",
    "X_test_selected = X_test_normalized[:, selected_features_indices]\n",
    "class_weights=  {0: 1, 1: 1}\n",
    "\n",
    "base_learners = [\n",
    "    ('gbt', GradientBoostingClassifier(n_estimators=100, subsample=0.8, max_features=0.8, random_state=42)),   \n",
    "    ('DecisionTree', DecisionTreeClassifier()),\n",
    "    ('XGBoost', XGBClassifier()),\n",
    "    ('CatBoost', CatBoostClassifier(silent=True)),]\n",
    "\n",
    "meta_classifier = classifier = LGBMClassifier(class_weight=class_weights,learning_rate=0.8, max_depth=6, n_estimators=20, num_leaves=20)\n",
    "# Training the LGBMClassifier model with the best hyperparameters\n",
    "\n",
    "stacking_model = StackingClassifier(estimators=base_learners, final_estimator=meta_classifier, cv=5, stack_method='predict_proba')\n",
    "\n",
    "stacking_model.fit(X_train_selected, y_train_resampled)\n",
    "predictions = stacking_model.predict(X_test_selected)\n",
    "probabilities = stacking_model.predict_proba(X_test_selected)[:, 1]  # For binary classification\n",
    "\n",
    "# Converting y_test to integer if necessary\n",
    "y_test = y_test.astype(int)\n",
    "\n",
    "# Calculating and displaying the AUC-ROC score for binary classification\n",
    "auc_roc = roc_auc_score(y_test, probabilities)\n",
    "\n",
    "print(\"AUC-ROC Score:\", auc_roc)\n",
    "\n",
    "# Displaying the results\n",
    "print(\"Feature Selector: SelectFromModel_GB, Classifier: LGBM\")\n",
    "print(classification_report(y_test, predictions))\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "\n",
    "# Performing k-fold cross-validation only on the training set\n",
    "cv_scores = cross_val_score(classifier, X_train_selected, y_train_resampled, cv=5, scoring='roc_auc')\n",
    "\n",
    "# Displaying cross-validation results\n",
    "print(\"Cross-Validation Scores:\", cv_scores)\n",
    "print(\"Mean CV Score:\", np.mean(cv_scores))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
